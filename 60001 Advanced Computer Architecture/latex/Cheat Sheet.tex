
\documentclass[a4paper, 5pt, twocolumn]{article}
\usepackage[top = 1.5cm, left=1.5cm, right=1cm, bottom = 1.cm]{geometry}
\usepackage[utf8]{inputenc}               
\usepackage[english]{babel}    
\usepackage{lipsum}
\usepackage{makecell}
\usepackage[pdfstartview=FitH]{hyperref}
\usepackage{bookmark}
\usepackage{graphicx}
\usepackage{enumitem}
\begin{document}
\setlength{\parindent}{0pt}
\hypertarget{branch-prediction}{%
\subsection{Branch Prediction}\label{branch-prediction}}

Simple predictors re-learn faster Sophisticated predictors re-learn
slower Selective predictors may choose faster learning predictors until
better predictor \textbf{\emph{warms up.}} \\

Branch Folding: Instead of just the branch target address in the
{[}{[}Branch Target Buffer{]}{]}, store the entire target
\emph{instruction}. \\

This way, you can skip the Instruction Fetch stage for the next
instruction, so the effective CPI for the branch is zero. \\

Could stash target instruction for both taken and not-taken to reduce
mispredicition delay. \\

BTB is:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
 \item \textbf{\emph{Indexed}} with low-order PC address bits 
 \item \textbf{\emph{Tagged}} with high-order PC address bits \\
\end{itemize} 

If a slower, direction predictor differs, re-steer: 
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Squash first prediction by re-writing PC 
	\item Fetch from improved prediction \\
\end{itemize} 

Updating the branch predictor:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Can update BTB as \textbf{SOON} as branch outcome is known (before committing)
	\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
		\item This means that later branches have correct BTB predictions. 
	\end{itemize}
	\item Update BTB after commit - just	in case of a branch misprediction. \\
\end{itemize}

\hypertarget{cache}{%
\subsection{Cache}\label{cache}}

Smaller caches -\textgreater{} Reduced hit time \\

Way prediction - extra bits are kept in the cache to predict the way of
the \emph{next} cache access. Means that you can access the correct set
for the desired way first on a correct prediction, getting the
performance benefit of direct-mapped caches (better hit time) and good
hit rate with associativity. \\

Multiple banks in L2 allows for {[}{[}Non-Blocking Caches{]}{]} to use
hit-under miss on cache miss (can service cache hit at the same time) \\

Early restart:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Processor can continue as soon as requested word arrives 
	\item restart CPU as soon as the requested word of the block arrives. 
	\item Request the missing word first (critical word first) - Useful in large blocks 
	\item Divide cache line into sectors - each with its own validity bit. \\
\end{itemize}

Write buffers:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item {[}{[}Write Through{]}{]} and {[}{[}Write Back{]}{]} caches rely on write buffers, to contain all stores that must be sent to the next level of the memory hierarchy. 
	\item -Coalescing write buffers - Merge adjacent writes into single entry
	\item Write merging - Merges consecutive word writes to memory addresses to take up less space in the write buffer 
	\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
		\item Reduces stalls, less space taken up in the write buffer 
		\item Takes advantage of spatial locality (writing) \\
	\end{itemize}
\end{itemize}

Hardware Prefetcing: Extra block fetched placed in a
\textbf{\emph{stream buffer}}. After a cache miss, the stream buffer
prefetches the \textbf{next} successive cache line. \\

On future misses, check the head of the stream buffer: 
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item If a hit, allocate into cache and prefetch the next line for the stream buffer
 	\item If a miss, clear the stream buffer and start over. \\
\end{itemize}
Relies on having \textbf{extra memory bandwidth}.

Have multiple stream buffers - because programs often make interleaved,
sequential streams of accesses. \\

Skewed-Associative Cache: Reduce conflict misses by using
\emph{different} indices in each cache way. Hash the cache index and
some tag bits (i.e.~XOR) As the indexes are pseudo random, conflict
misses are reduced as they don't map to the same index anymore
-\textgreater{} useful for loops. \\

Costs:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Must have an address decoder per way 
	\item Latency of hash function
	\item Harder to implement LRU \\
\end{itemize}

\hypertarget{sidechannels}{%
\subsection{Sidechannels}\label{sidechannels}}

Evict and Time: 
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Let victim run 
	\item Attacker evicts line of interest  
	\item Let victim run again, measure difference in time to find if attacker affected it \\
\end{itemize}
Flush and Reload:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
 \item Attacker evicts line of interest 
 \item Victim executes 
 \item Attacker reloads evicted line 
 \item Fast reload  
 \item victim touched the line, cache tag was used 
 \item Slow reload 
 \item cache tag was not used by victim\\
\end{itemize}
Prime and Probe:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
 \item Attacker primes cache 
 \item Victim executes, attacker times access to its own cache lines \\
\end{itemize}
\hypertarget{loads-stores}{%
\subsection{Loads \& Stores}\label{loads-stores}}

Need to \textbf{STALL} loads until all possibly aliasing store addresses
are known. \\

As loads and stores use \textbf{COMPUTED ADDRESSES}, they may not be
known at issue time, so any store / load instruction could be a data
dependence (RAW). Could wait as above, or:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
 \item Speculate whether it is or isn't 
 \item then check for misprediction 
 \item Add a fowarding predictor to improve this speculation \\
\end{itemize}

Allow a load to proceed \textbf{BEFORE} we know for sure if / which any
prior uncommited store instruction writes to its address. \\

Can use the idea of \textbf{store-wait} (Alpha 21264): 
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Guess that ,there is no memory dependence 
	\item Squash if there is, and mark the load instruction as \emph{store-wait} in the load unit 
	\item Next time that load is needed, it will wait for all previous stores to complete \\
\end{itemize}

Can also use the idea of a store set to further improve this, so that
you're not waiting on EVERY store. \\

Store unit can mark entries as valid / speculative, so speculative
instructions aren't stored in memory. \\

\hypertarget{return-address-stack}{%
\subsection{Return Address Stack}\label{return-address-stack}}

After decode, the instruction is checked:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	 \item If JSR, add PC to RAS 
	 \item If ret, pop RAS, prediction was correct \\
\end{itemize}

If the call stack is deeper than the RAS: 
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item RAS will be empty at some point 
	\item stack overflow 
	\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
		\item RAS prediction may be wrong: - Switching threads would change the stack pointer \\
	\end{itemize}
\end{itemize}

Updating the RAS:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item On commit - might not have a prediction in time for addresses deeper in the stack. \\
\end{itemize}

If a conditional branch is mispredicted, and inside the taken version of
that branch is a function call, then a return address is going to be
pushed onto the stack. \\

To mitigate this and optimise for loops - we can have a shift register
that records \emph{prediction state}. \\

On every prediction, every time we hit a JSR instruction, we increment
this register and let it push a return address onto the stack. \\

If we suffer a misprediction - we pop the RAS n times, where n is the
value in this shift register, and we're back to the original state. \\

BTB entries would be affected though -\textgreater{} we'd have entries
for return addresses when they shouldn't be there. That's fine though -
as we shouldn't get to those return addresses unless we were supposed to
be there, assuming there are no erroneous jumps. \\

\hypertarget{vector-instructions}{%
\subsection{Vector Instructions:}\label{vector-instructions}}

\begin{itemize} [topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item
  Less fetching from instruction cache, but exploits parallelism
\item
  Lanes execute in parallel
\item
  Have vector predicate registers (512 bit wide - 1 bit per lane)
\item
  Zero masking - when predicate is false, register for lane set to 0
\item
  Masking - when predicate is false, register for lane retains old value
\item
  If trip count is not divisible by vector instruction, need additional
  non-vector instruction to mop up
\item
  If arrays are potentially aliased or are data dependent, cannot use
  vector instructions
\item
  Use `gather' instruction for indirect array indexing
\item
  If the alignment of the operand pointers is not known, need
  instructions to align onto a 32 byte boundary
\end{itemize}

\hypertarget{cache-coherency}{%
\subsection{Cache Coherency}\label{cache-coherency}}

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item
  If reading:

  \begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
  \item
    If another cache has dirty or shared-dirty, get from cache using
    bus-read
  \item
    They set to shared-dirty, you set to valid
  \item
    Else valid from memory
  \end{itemize}
\item
  If writing:

  \begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
  \item
    No action if dirty
  \item
    if valid or shared-dirty, send invalidation on bus, set ours to
    dirty
  \item
    On miss - line comes from owner, everyone else set to invalid
  \end{itemize}
\item
  Cache controllers send out signals
\item
  duplicate tags in L1 to allow for parallel checks - or check in L2
  with multilevel inclusion
\end{itemize}

\hypertarget{gpus}{%
\subsection{GPUs}\label{gpus}}

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item
  SIMD but on multiple threads
\item
  Each SM uses FGMT on each warp (thread on CPU)
\item
  Each warp using 32-bit wide SIMD vector instruction for lanes (in
  lockstep)
\item
  If threads in a warp diverge, bad for spatial locality
\end{itemize}
\section{Sonic Boom}
\hypertarget{instructionfetchstage}{%
\subsection{Instruction Fetch Stage}\label{instructionfetchstage}}

Additional pipeline stage is added after the frontend-decoders shift the decoded instructions into a dense fetch packet:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Needed to pass into the backend
	\item Provides an interface - decoder always gets 4 instructions, even if 4-8 instructions are issued
	\item Overflow of instructions (fetched instructions - 4) are stored in the fetch buffer \\
\end{itemize}

Next Line Predictor (micro-BTB):
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Small, fully-associative cache that stores branch address and target address
	\item Can be improved with [[Branch Folding]]
	\item Improves fetch throughput on small-bodied loops (JMP to top predicted) \\
\end{itemize}

Repair mechanisms - restores predictor state after misspeculation:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Loop-predictor and RAS are snapshotted and repaired on mispredict
	\item Maybe use a RAS pop shift register? \\
\end{itemize}

Superscalar branch resolution, with multiple branch resolution units:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
 \item Handles when multiple branches are in the same packet
 \item Additional pipeline stage after WB to read the fetch-PC queue - a queue for PCs to fetch soon - and determine the target address for the oldest mispredicted branch from a vector of branch mispredictions
 \item Allows for aggressive scheduling of branches - don't need to wait for a branch resolution unit to finish \\
\end{itemize}

TAGE:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item High accuracy for dense areas with many conditional branches
	\item Provides bit vector of taken / not taken, each bit for each instruction in the fetch packet
	\item Updated during commit stage \\
\end{itemize}

\hypertarget{Execute Stage}{%
\subsection{Instruction Fetch Stage}\label{executestage}}

SFB recorder:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Records difficult to predict branches into internal predicated microOps
	\item Detects short-forwards and translates into set-flag and conditionally execute instructions
	\item Set-flag writes outcome of branch to predicate register
	\item Conditionally execute either
	\item \begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
		\item True - Executes instruction and places into target register
		\item False - Copies original value of (stale physical) destination register into physical destination register \\
	\end{itemize}
\end{itemize}

\hypertarget{loadstorestage}{%
\subsection{Instruction Fetch Stage}\label{loadstorestage}}

Dual Ported L1 Data cache:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Two banks - for odd and even addresses (implemented as 1R1W SRAMs)
	\item Good with load-heavy bursts
	\item Can use [[Loads \& Stores]] - memory dependence prediction
	\item Is a [[Non-Blocking Caches]] \\
\end{itemize}

Line-fill buffers:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Cache requests to populate the line-fill buffer
	\item Allows for cache eviction and requests to happen in parallel
	\item Flushed into L1 Dcache when evictions are complete
	\item Misspeculated cache refills stay in line-fill buffers, which means they must be searched in parallel
	\item Flushed on context switch?
	\item Uses a next-line prefetcher - [[Hardware Prefetching]] - after a cache miss
	\item Updates L1 Dcache during speculation window - if there are no cache evictions in queue \\
\end{itemize}

\hypertarget{sidechannelvulnerabilities}{%
\subsection{Side Channel Vulnerabilities}\label{sidechannelvulnerabilities}}
SonicBOOM vulnerabilities - speculative execution changes the microarchitectural state temporarily:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Spectre-v1: bypassing bounds checks
	\item Spectre-v2: branch target injection
	\item Spectre-v5: return stack buffer attack \\
\end{itemize}

Issues with Load / Store Unit:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item 3 cycle delay to allocate misses in the MSHRs and request data from L2
	\item Loads are optimistically fired to use OoO execution \\
\end{itemize}

Attack methodology:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Attacker establish desired conditions
	\item Trigger victim execution with invalid instruction
	\item Victim loads secret into covert channel (data cache)
	\item Processor resets pipeline by squashing and rolling back
	\item Attacker probes data cache for information (flush + reload) \\
\end{itemize}

Bypassing Bounds Checks:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Mis-train conditional branch direction prediction
	\item Trigger using a conditional branch \\
\end{itemize}

Branch Target Injection:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Mis-train BTB for branch target prediction
	\item Trigger using a call to a mis-speculated target (malicious function)\\
\end{itemize}

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Mis-train BTB for branch target prediction
	\item Trigger using a call to a mis-speculated target (malicious function)\\
\end{itemize}

Return Stack Buffer Attack:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Craft malicious gadget after a call site
	\item Trigger using a return, as exploiting RAS miss-match with software stack\\
\end{itemize}

RIDL (Line Buffers - MDS Attacks)\\

\bf Mitigations:\\
Speculative Taint Tracking:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Allow OoO execution
	\item Destination of speculative load is marked as tainted in a hardware taint file
	\item Subsequent loads that use tainted addresses activate data memory fencing for all loads in the LSQ (fence\_dmem).
	\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
		\item This is detected at AGU (memaddrcalc)
		\item All loads in LSQ - as we are in danger zone
	\end{itemize}
	\item Also notifies frontend to send out dispatch hazards (dis), forcing the pipeline to stall and the processor to run in order temporarily.
	\item When fencing used, data cache refill is temporarily disabled and MSHRs are cleared until load is no longer speculative (and data is untainted)
	\item Untaint when instruction is commitable
	\item On misprediction, data in tainted registers is invalid
\end{itemize}

Retpolines:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item Use a direct branch to a function that evaluates the indirect address and places it in a register, using a call instruction
	\item Ret back once evaluated
	\item Removes need for target address speculation
\end{itemize}

Cache formula: log2(cache line size) = offset bits log2(cache size / no of ways * address bits) = index bits tag bits = address bits - offset bits - index bits
\end{document}